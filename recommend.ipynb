{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whziOdRsoWWx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.spatial.distance import cosine\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\"\"\"\n",
        "Hybrid Recommendation System for Product Images and Metadata\n",
        "\n",
        "This script builds a hybrid recommendation system that leverages both image features\n",
        "(using VGG16 pre-trained CNN) and text metadata (TF-IDF vectorization).\n",
        "It combines these features to recommend similar products based on a given input product.\n",
        "\n",
        "Key Features:\n",
        "1. **Image Features**: Extracted using VGG16 pre-trained model.\n",
        "2. **Text Metadata**: Processed using TF-IDF Vectorizer.\n",
        "3. **Hybrid Similarity**: Weighted combination of image and text similarities.\n",
        "4. **Visualization**: Displays input product and recommended products as images.\n",
        "\n",
        "Dependencies:\n",
        "- TensorFlow\n",
        "- scikit-learn\n",
        "- matplotlib\n",
        "- pandas\n",
        "- PIL\n",
        "- tqdm\n",
        "\"\"\"\n",
        "\n",
        "# ----------------------------\n",
        "# Step 1: Load Metadata\n",
        "# ----------------------------\n",
        "# Load the metadata file (CSV format)\n",
        "data = pd.read_csv('your_metadata_file.csv')\n",
        "\n",
        "# Drop unneeded columns (e.g., Product URL)\n",
        "data = data.drop(['Product URL'], axis=1)\n",
        "\n",
        "# ----------------------------\n",
        "# Step 2: Image Feature Extraction\n",
        "# ----------------------------\n",
        "# Initialize VGG16 model for feature extraction\n",
        "base_model = VGG16(weights='imagenet', include_top=False)\n",
        "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
        "\n",
        "def preprocess_img(img_path):\n",
        "    \"\"\"\n",
        "    Preprocess the input image to match VGG16 input requirements.\n",
        "    Args:\n",
        "        img_path (str): Path to the image file.\n",
        "    Returns:\n",
        "        np.array: Preprocessed image array.\n",
        "    \"\"\"\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array_expanded = np.expand_dims(img_array, axis=0)\n",
        "    return preprocess_input(img_array_expanded)\n",
        "\n",
        "def extract_features(img_path):\n",
        "    \"\"\"\n",
        "    Extract features from the image using VGG16.\n",
        "    Args:\n",
        "        img_path (str): Path to the image file.\n",
        "    Returns:\n",
        "        np.array: Flattened and normalized image features.\n",
        "    \"\"\"\n",
        "    img = preprocess_img(img_path)\n",
        "    features = model.predict(img)\n",
        "    flattened_features = features.flatten()\n",
        "    return flattened_features / np.linalg.norm(flattened_features)\n",
        "\n",
        "# Extract image features for all images\n",
        "image_features = []\n",
        "image_paths = []\n",
        "for img_path in tqdm(data['Image Path']):\n",
        "    if os.path.exists(img_path):\n",
        "        features = extract_features(img_path)\n",
        "        image_features.append(features)\n",
        "        image_paths.append(img_path)\n",
        "    else:\n",
        "        # Placeholder for missing images\n",
        "        image_features.append(np.zeros((7 * 7 * 512)))\n",
        "\n",
        "data['Image Features'] = image_features\n",
        "\n",
        "# ----------------------------\n",
        "# Step 3: Text Feature Extraction\n",
        "# ----------------------------\n",
        "# Combine textual metadata columns\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "text_data = data['Product Name'] + ' ' + data['Brand'] + ' ' + data['Category'].astype(str)\n",
        "tfidf_matrix = vectorizer.fit_transform(text_data)\n",
        "\n",
        "# ----------------------------\n",
        "# Step 4: Hybrid Recommendation Function\n",
        "# ----------------------------\n",
        "def get_recommendations(input_index, data, tfidf_matrix, top_n=5):\n",
        "    \"\"\"\n",
        "    Recommend similar products based on hybrid similarity (image + text).\n",
        "    Args:\n",
        "        input_index (int): Index of the input product.\n",
        "        data (DataFrame): Product metadata and features.\n",
        "        tfidf_matrix (sparse matrix): TF-IDF matrix of text metadata.\n",
        "        top_n (int): Number of recommendations to display.\n",
        "    \"\"\"\n",
        "    # Extract input features\n",
        "    input_image_features = data['Image Features'][input_index]\n",
        "    input_text_vector = tfidf_matrix[input_index]\n",
        "\n",
        "    # Compute cosine similarities\n",
        "    image_similarities = [1 - cosine(input_image_features, features) for features in data['Image Features']]\n",
        "    text_similarities = cosine_similarity(input_text_vector, tfidf_matrix).flatten()\n",
        "\n",
        "    # Combine similarities (weighted sum)\n",
        "    combined_similarity = 0.6 * np.array(image_similarities) + 0.4 * text_similarities\n",
        "\n",
        "    # Sort indices by similarity, excluding the input product itself\n",
        "    similar_indices = np.argsort(combined_similarity)[::-1]\n",
        "    similar_indices = [i for i in similar_indices if i != input_index]\n",
        "\n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(nrows=top_n + 1, ncols=1, figsize=(6, 10))\n",
        "    if top_n == 1:\n",
        "        axes = [axes]  # Ensure axes is iterable for single recommendation\n",
        "\n",
        "    # Display input product\n",
        "    img = Image.open(data['Image Path'][input_index])\n",
        "    axes[0].imshow(img)\n",
        "    axes[0].axis('off')\n",
        "    axes[0].set_title(f\"Input Product: {data['Product Name'][input_index]}\\nPrice: {data['Offer Price'][input_index]}\")\n",
        "\n",
        "    # Display recommended products\n",
        "    for i, idx in enumerate(similar_indices[:top_n]):\n",
        "        img = Image.open(data['Image Path'][idx])\n",
        "        axes[i + 1].imshow(img)\n",
        "        axes[i + 1].axis('off')\n",
        "        axes[i + 1].set_title(f\"{data['Product Name'][idx]}\\nPrice: {data['Offer Price'][idx]}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ----------------------------\n",
        "# Step 5: Example Usage\n",
        "# ----------------------------\n",
        "# Recommend similar products for a given product (e.g., first product in the dataset)\n",
        "get_recommendations(0, data, tfidf_matrix, top_n=5)"
      ]
    }
  ]
}